{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7e4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180fa88e",
   "metadata": {},
   "source": [
    "```\n",
    "pip install sqlalchemy psycopg2-binary \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1096f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523f5cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c509ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM pg_catalog.pg_tables\n",
    "WHERE schemaname != 'pg_catalog' AND \n",
    "    schemaname != 'information_schema';\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d72b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in parquet files and output as CSV \n",
    "# trips = pq.read_table('yellow_tripdata_2019-09.parquet')\n",
    "# df_trips = trips.to_pandas()\n",
    "\n",
    "df = pd.read_csv('green_tripdata_2019-09.csv',nrows=100)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68fb665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop over to try and  get data into postgres -CSV --> green_tripdata\n",
    "from time import time\n",
    "\n",
    "#show time started\n",
    "print(\"Started: %s\" % datetime.datetime.now())\n",
    "\n",
    "#reading in CSV\n",
    "df_iter = pd.read_csv('green_tripdata_2019-09.csv',iterator=True,chunksize=100000 ,low_memory=False)\n",
    "for batch in df_iter:\n",
    "    t_start = time()\n",
    "    \n",
    "    df = batch\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "    df.to_sql(name='green_tripdata_trip', con=engine, if_exists=\"append\")\n",
    "    \n",
    "    t_end = time()  \n",
    "    print(\"New chunk inserted: %.3f elapsed\" % (t_end - t_start))\n",
    "\n",
    "print(\"Ended: %s\" % datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173392e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop over to try and  get data into postgres -CSV --> taxi+_zone_lookup.csv\n",
    "#wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv\n",
    "\n",
    "from time import time\n",
    "\n",
    "#show time started\n",
    "print(\"Started: %s\" % datetime.datetime.now())\n",
    "\n",
    "#reading in CSV\n",
    "df_iter = pd.read_csv('taxi+_zone_lookup.csv',iterator=True,chunksize=100000 ,low_memory=False)\n",
    "for batch in df_iter:\n",
    "    t_start = time()\n",
    "    \n",
    "    df = batch\n",
    "    df.to_sql(name='taxi_zone', con=engine, if_exists=\"append\")\n",
    "    \n",
    "    t_end = time()  \n",
    "    print(\"New chunk inserted: %.3f elapsed\" % (t_end - t_start))\n",
    "\n",
    "print(\"Ended: %s\" % datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f388bb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop over to try and  get data into postgres - parquet\n",
    "from time import time\n",
    "\n",
    "#show time started\n",
    "print(\"Started: %s\" % datetime.datetime.now())\n",
    "\n",
    "#reading in parquet\n",
    "parquet_file = pq.ParquetFile('green_tripdata_2019-09.parquet')\n",
    "for batch in parquet_file.iter_batches(batch_size=100000):\n",
    "    t_start = time()\n",
    "    \n",
    "    df = batch.to_pandas()\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "    df.to_sql(name='green_tripdata_trip', con=engine, if_exists=\"append\")\n",
    "    \n",
    "    t_end = time()  \n",
    "    print(\"New chunk inserted: %.3f elapsed\" % (t_end - t_start))\n",
    "    \n",
    "print(\"Ended: %s\" % datetime.datetime.now())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
